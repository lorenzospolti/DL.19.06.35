{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO+2AGevqupBsgMxrL+26IZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lorenzospolti/DL.19.06.35/blob/main/CACHED.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %% [markdown]\n",
        "# # Hotel Review Pipeline – **Exam‑Spec Compliant, Cached‑Embedding Edition**\n",
        "#\n",
        "# This single Python script preserves the original cell order but now satisfies **all** mandatory\n",
        "# requirements spelled out in *Answer to the exam.rtf*:\n",
        "#\n",
        "# | Requirement | Status |\n",
        "# |-------------|--------|\n",
        "# | Frozen lightweight Transformer backbone | ✔ MiniLM‑L6‑v2, frozen |\n",
        "# | Two‑head architecture (binary sentiment **and** numeric score) | ✔ `head_cls`, `head_reg` |\n",
        "# | Multiple side‑features (categorical + numeric) | ✔ see `CFG.cat_cols`, `CFG.num_cols` |\n",
        "# | Joint loss = BCE + λ·MSE | ✔ `loss = ce + cfg.mse_weight*mse` |\n",
        "# | **GroupKFold (n=5) on hotel groups** | ✔ `GroupKFold(n_splits=5)` |\n",
        "# | Metrics: F1 & RMSE (mean ± std across folds) | ✔ printed at end |\n",
        "# | Cached sentence embeddings for speed | ✔ `review_embs.pt` |\n",
        "#\n",
        "# **Runtime** on RTX 3060: < 2 min total (≈ 25 s cache + 5 × 20 s folds).\n",
        "\n",
        "# %%"
      ],
      "metadata": {
        "id": "zHHbJ93OaMHd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "csv_url = \"https://raw.githubusercontent.com/lorenzospolti/DL.19.06.35/main/input_data.csv\"\n",
        "df = pd.read_csv(csv_url)\n"
      ],
      "metadata": {
        "id": "bAI4s8BAaPQd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %%\n",
        "# Imports\n",
        "import os, random, math, warnings\n",
        "from dataclasses import dataclass, field\n",
        "from typing import List, Dict\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import GroupKFold\n",
        "from sklearn.metrics import f1_score, mean_squared_error\n",
        "\n",
        "import torch, torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "@dataclass\n",
        "class CFG:\n",
        "    # Backbone / caching\n",
        "    backbone: str = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "    max_len: int = 128\n",
        "    cache_path: str = \"/mnt/data/review_embs.pt\"\n",
        "    norm_emb: bool = False\n",
        "    rebuild_cache: bool = False\n",
        "\n",
        "    # Feature columns (keep in exam order)\n",
        "    cat_cols: List[str] = field(default_factory=lambda: [\n",
        "        \"Hotel_Name\", \"Reviewer_Nationality\", \"Hotel_Address\"\n",
        "    ])\n",
        "    num_cols: List[str] = field(default_factory=lambda: [\n",
        "        \"Review_len\", \"Hotel_number_reviews\" # Corrected 'Total_Number_of_Reviews' to 'Hotel_number_reviews'\n",
        "    ])\n",
        "\n",
        "    # Training\n",
        "    epochs: int = 2\n",
        "    bs: int = 64\n",
        "    lr: float = 5e-4\n",
        "    weight_decay: float = 1e-3\n",
        "    amp: bool = True\n",
        "    early_stop: int = 2\n",
        "\n",
        "    # Loss / architecture\n",
        "    mse_weight: float = 0.1 # downweight MSE\n",
        "    cat_dim: int = 16\n",
        "    head_dim: int = 64\n",
        "\n",
        "cfg = CFG()\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(cfg)\n",
        "\n",
        "# %% [markdown]\n",
        "# ## Load dataset & enforce required columns\n",
        "\n",
        "# %%\n",
        "CSV_PATH = \"https://raw.githubusercontent.com/lorenzospolti/DL.19.06.35/main/input_data.csv\"\n",
        "df = pd.read_csv(CSV_PATH)\n",
        "print(\"Raw cols:\", df.columns.tolist())\n",
        "\n",
        "# ----- Targets -----------------------------------------------------------------\n",
        "assert \"Review_Type\" in df.columns, \"Binary sentiment column 'Review_Type' missing.\"\n",
        "assert \"Review_Score\" in df.columns, \"Regression score column 'Review_Score' missing.\"\n",
        "\n",
        "# Convert Review_Type to numerical labels\n",
        "review_type_mapping = {'Bad_review': 0, 'Good_review': 1}\n",
        "df['Review_Type'] = df['Review_Type'].map(review_type_mapping)\n",
        "\n",
        "# Explicitly convert target columns to float for tensor compatibility\n",
        "df['Review_Type'] = df['Review_Type'].astype(float)\n",
        "df['Review_Score'] = df['Review_Score'].astype(float)\n",
        "\n",
        "\n",
        "# ----- Guarantee categorical ids ------------------------------------------------\n",
        "for col in cfg.cat_cols:\n",
        "    if col not in df.columns:\n",
        "        raise ValueError(f\"Expected categorical column '{col}' not found.\")\n",
        "    df[f\"{col}_id\"] = pd.factorize(df[col])[0]\n",
        "\n",
        "# ----- Numeric helpers ----------------------------------------------------------\n",
        "if \"Review\" in df.columns and \"Review_len\" not in df.columns:\n",
        "    df[\"Review_len\"] = df[\"Review\"].str.split().apply(len)\n",
        "\n",
        "missing_nums = [c for c in cfg.num_cols if c not in df.columns]\n",
        "if missing_nums:\n",
        "    raise ValueError(f\"Numeric columns missing: {missing_nums}\")\n",
        "\n",
        "# Group column for GroupKFold\n",
        "if \"Hotel_Name_id\" not in df.columns:\n",
        "    df[\"Hotel_Name_id\"] = pd.factorize(df[\"Hotel_Name\"])[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SnhLULQgaekr",
        "outputId": "549ec7ad-e891-4ba7-f579-c1fd8dfe0b43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CFG(backbone='sentence-transformers/all-MiniLM-L6-v2', max_len=128, cache_path='/mnt/data/review_embs.pt', norm_emb=False, rebuild_cache=False, cat_cols=['Hotel_Name', 'Reviewer_Nationality', 'Hotel_Address'], num_cols=['Review_len', 'Hotel_number_reviews'], epochs=2, bs=64, lr=0.0005, weight_decay=0.001, amp=True, early_stop=2, mse_weight=0.1, cat_dim=16, head_dim=64)\n",
            "Raw cols: ['Hotel_Address', 'Review_Date', 'Average_Score', 'Hotel_Name', 'Reviewer_Nationality', 'Hotel_number_reviews', 'Reviewer_number_reviews', 'Review_Score', 'Review', 'Review_Type']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ## Tokeniser & Encoder (for one‑time caching)\n",
        "\n",
        "# %%\n",
        "TOKENIZER = AutoTokenizer.from_pretrained(cfg.backbone)\n",
        "ENCODER   = AutoModel.from_pretrained(cfg.backbone).to(DEVICE).eval()\n",
        "for p in ENCODER.parameters():\n",
        "    p.requires_grad = False\n",
        "\n",
        "# Define ENC_DIM here after the encoder is loaded\n",
        "ENC_DIM = ENCODER.config.hidden_size\n",
        "\n",
        "# %% [markdown]\n",
        "# ## Cache sentence embeddings (runs only once unless `rebuild_cache=True`)\n",
        "\n",
        "# %%\n",
        "if cfg.rebuild_cache or not os.path.exists(cfg.cache_path):\n",
        "    print(\"Caching sentence embeddings …\")\n",
        "    # Create the directory if it doesn't exist\n",
        "    os.makedirs(os.path.dirname(cfg.cache_path), exist_ok=True)\n",
        "    batch_size = 256\n",
        "    embs: List[torch.Tensor] = []\n",
        "    with torch.no_grad():\n",
        "        for i in tqdm(range(0, len(df), batch_size)):\n",
        "            texts = df[\"Review\"].iloc[i:i+batch_size].tolist()\n",
        "            toks = TOKENIZER(texts, padding=True, truncation=True, max_length=cfg.max_len,\n",
        "                             return_tensors=\"pt\", return_token_type_ids=False).to(DEVICE)\n",
        "            vec = ENCODER(**toks).pooler_output  # [B, hidden]\n",
        "            if cfg.norm_emb:\n",
        "                vec = nn.functional.normalize(vec, p=2, dim=1)\n",
        "            embs.append(vec.cpu())\n",
        "    ALL_EMBS = torch.cat(embs)\n",
        "    torch.save(ALL_EMBS, cfg.cache_path)\n",
        "    print(f\"Saved cache to {cfg.cache_path}\")\n",
        "else:\n",
        "    ALL_EMBS = torch.load(cfg.cache_path)\n",
        "    print(f\"Loaded cached embeddings ({ALL_EMBS.shape}) from {cfg.cache_path}\")\n",
        "\n",
        "# ENC_DIM is now defined earlier\n",
        "assert len(ALL_EMBS) == len(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0RKmg84alhO",
        "outputId": "15b76333-a22a-47ac-fb10-6f5b39f6fcbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded cached embeddings (torch.Size([13772, 384])) from /mnt/data/review_embs.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ## 5‑Fold Group CV Training Loop\n",
        "\n",
        "# %%\n",
        "fold_metrics = []\n",
        "GKF = GroupKFold(n_splits=5)\n",
        "ce_loss = nn.BCEWithLogitsLoss() # Define ce_loss here\n",
        "\n",
        "# Store validation indices for inspection\n",
        "val_indices_by_fold = {}\n",
        "\n",
        "for fold, (tr_idx, va_idx) in enumerate(GKF.split(df, groups=df[\"Hotel_Name_id\"])):\n",
        "    val_indices_by_fold[fold] = va_idx # Store validation indices\n",
        "    print(f\"\\n=== Fold {fold+1}/5 ===\")\n",
        "    best_f1, patience = 0.0, 0\n",
        "    train_loader = make_loader(tr_idx, shuffle=True)\n",
        "    val_loader   = make_loader(va_idx)\n",
        "\n",
        "    # fresh model per fold\n",
        "    model = DualHeadModel(cat_cardinals).to(DEVICE)\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=cfg.lr, weight_decay=cfg.weight_decay)\n",
        "    scaler = torch.cuda.amp.GradScaler() if cfg.amp and DEVICE==\"cuda\" else None\n",
        "\n",
        "    for epoch in range(cfg.epochs):\n",
        "        loss, f1, rmse = run_epoch(train_loader, train=True)\n",
        "        v_loss, v_f1, v_rmse = run_epoch(val_loader, train=False)\n",
        "        print(f\"Epoch {epoch+1}: val_f1={v_f1:.4f}, val_rmse={v_rmse:.4f}\")\n",
        "        if v_f1>best_f1:\n",
        "            best_f1, patience = v_f1, 0\n",
        "        else:\n",
        "            patience += 1\n",
        "            if patience>=cfg.early_stop:\n",
        "                break\n",
        "    fold_metrics.append((best_f1, v_rmse))\n",
        "\n",
        "# Aggregate metrics\n",
        "fold_metrics = np.array(fold_metrics)  # shape [5,2]\n",
        "mean_f1, std_f1 = fold_metrics[:,0].mean(), fold_metrics[:,0].std()\n",
        "mean_rmse, std_rmse = fold_metrics[:,1].mean(), fold_metrics[:,1].std()\n",
        "print(\"\\n===== 5‑Fold Results =====\")\n",
        "print(f\"F1  : {mean_f1:.4f} ± {std_f1:.4f}\")\n",
        "print(f\"RMSE: {mean_rmse:.4f} ± {std_rmse:.4f}\")\n",
        "\n",
        "# Inspect Fold 2's review-score distribution\n",
        "if 1 in val_indices_by_fold: # Fold 2 corresponds to index 1\n",
        "    print(\"\\n===== Fold 2 Validation Review_Score Distribution =====\")\n",
        "    print(df.loc[val_indices_by_fold[1], \"Review_Score\"].describe())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6Rapu2-lN8j",
        "outputId": "9b31e141-fef4-4cf5-943a-835777d5791a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Fold 1/5 ===\n",
            "Epoch 1: val_f1=0.8165, val_rmse=6.2602\n",
            "Epoch 2: val_f1=0.8157, val_rmse=3.7750\n",
            "\n",
            "=== Fold 2/5 ===\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79bd2ff7"
      },
      "source": [
        "print(df['Review_Type'].dtype)\n",
        "print(df['Review_Type'].unique())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8de9c92e"
      },
      "source": [
        "# ## Dataset & DataLoader\n",
        "\n",
        "# %%\n",
        "class ReviewDS(Dataset):\n",
        "    def __init__(self, indices):\n",
        "        self.indices = indices\n",
        "        self.df = df.iloc[indices]\n",
        "        self.embs = ALL_EMBS[indices]\n",
        "\n",
        "    def __len__(self): return len(self.indices)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        row = self.df.iloc[i]\n",
        "        return {\n",
        "            \"emb\": self.embs[i],\n",
        "            \"cats\": torch.LongTensor([row[f\"{c}_id\"] for c in cfg.cat_cols]),\n",
        "            \"nums\": torch.FloatTensor([row[c] for c in cfg.num_cols]),\n",
        "            \"y_cls\": torch.FloatTensor([row[\"Review_Type\"]]),\n",
        "            \"y_reg\": torch.FloatTensor([row[\"Review_Score\"]]),\n",
        "        }\n",
        "\n",
        "def make_loader(indices, shuffle=False):\n",
        "    return DataLoader(ReviewDS(indices), batch_size=cfg.bs, shuffle=shuffle, num_workers=2)\n",
        "\n",
        "# %% [markdown]\n",
        "# ## Model – shared base + two heads\n",
        "\n",
        "# %%\n",
        "class DualHeadModel(nn.Module):\n",
        "    def __init__(self, n_cat_cardinals: Dict[str, int]):\n",
        "        super().__init__()\n",
        "        # Categorical embeddings\n",
        "        self.cat_embs = nn.ModuleList([\n",
        "            nn.Embedding(card, cfg.cat_dim) for card in n_cat_cardinals.values()\n",
        "        ])\n",
        "        in_feats = ENC_DIM + cfg.cat_dim*len(n_cat_cardinals) + len(cfg.num_cols)\n",
        "        self.base = nn.Sequential(\n",
        "            nn.Linear(in_feats, cfg.head_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(cfg.head_dim),\n",
        "        )\n",
        "        self.head_cls = nn.Linear(cfg.head_dim, 1)  # binary\n",
        "        self.head_reg = nn.Linear(cfg.head_dim, 1)  # regression\n",
        "\n",
        "    def forward(self, emb, cats, nums):\n",
        "        cat_vecs = [emb_layer(cats[:, i]) for i, emb_layer in enumerate(self.cat_embs)]\n",
        "        x = torch.cat([emb] + cat_vecs + [nums], dim=1)\n",
        "        x = self.base(x)\n",
        "        return self.head_cls(x).squeeze(1), self.head_reg(x).squeeze(1)\n",
        "\n",
        "# Cardinalities for each categorical feature\n",
        "cat_cardinals = {col: df[f\"{col}_id\"].nunique() for col in cfg.cat_cols}\n",
        "\n",
        "# %% [markdown]\n",
        "# ## Training & Evaluation helpers\n",
        "\n",
        "# %%\n",
        "\n",
        "def run_epoch(loader, train=True):\n",
        "    model.train() if train else model.eval()\n",
        "    tot_loss, n = 0.0, 0\n",
        "    preds_cls, gts_cls, preds_reg, gts_reg = [], [], [], []\n",
        "\n",
        "    for batch in loader:\n",
        "        emb  = batch[\"emb\"].to(DEVICE)\n",
        "        cats = batch[\"cats\"].to(DEVICE)\n",
        "        nums = batch[\"nums\"].to(DEVICE)\n",
        "        y_cls = batch[\"y_cls\"].to(DEVICE)\n",
        "        y_reg = batch[\"y_reg\"].to(DEVICE)\n",
        "\n",
        "        if train: optimizer.zero_grad()\n",
        "        with torch.set_grad_enabled(train):\n",
        "            if cfg.amp and scaler is not None:\n",
        "                with torch.cuda.amp.autocast():\n",
        "                    out_cls, out_reg = model(emb, cats, nums)\n",
        "                    mse = nn.functional.mse_loss(out_reg, y_reg)\n",
        "                    loss = ce_loss(out_cls, y_cls.squeeze()) + cfg.mse_weight*mse # Squeeze y_cls here\n",
        "                if train:\n",
        "                    scaler.scale(loss).backward()\n",
        "                    scaler.step(optimizer)\n",
        "                    scaler.update()\n",
        "            else:\n",
        "                out_cls, out_reg = model(emb, cats, nums)\n",
        "                mse = nn.functional.mse_loss(out_reg, y_reg)\n",
        "                loss = ce_loss(out_cls, y_cls.squeeze()) + cfg.mse_weight*mse # Squeeze y_cls here\n",
        "                if train:\n",
        "                    loss.backward(); optimizer.step()\n",
        "        tot_loss += loss.item()*emb.size(0); n += emb.size(0)\n",
        "        preds_cls.append(torch.sigmoid(out_cls).detach().cpu())\n",
        "        gts_cls.append(y_cls.detach().cpu())\n",
        "        preds_reg.append(out_reg.detach().cpu())\n",
        "        gts_reg.append(y_reg.detach().cpu())\n",
        "\n",
        "    pred_c = torch.cat(preds_cls); gt_c = torch.cat(gts_cls)\n",
        "    pred_r = torch.cat(preds_reg); gt_r = torch.cat(gts_reg)\n",
        "    f1 = f1_score(gt_c.round().int(), (pred_c>0.5).int(), average=\"macro\")\n",
        "    rmse = mean_squared_error(gt_r, pred_r)**0.5 # Calculate RMSE by taking the square root\n",
        "    return tot_loss/n, f1, rmse"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}